{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Юнит 8. Введение в нейронные сети\n",
    "### Skillfactory: DSPR-19\n",
    "### DL-2. Практика с основными фреймворками "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Уровни абстракции\n",
    "\n",
    "Самое время приступать к практике с основными фреймворками! В этом модуле мы научимся работать с двумя — **TensorFlow** и **PyTorch.**\n",
    "\n",
    "Но для начала разберёмся, насколько глубоко мы вообще можем погружаться в обучение нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует несколько уровней абстракции, на которых мы можем сконструировать нейросеть:\n",
    "\n",
    "- **Нижний уровень (NumPy)** — нет готовых высокоуровневых блоков, нет оптимизаторов, отсутствует возможность параллельных расчётов и использования GPU. Используется в учебных целях для иллюстрации принципов работы нейросетей.\n",
    "- **Фреймворки автоматического дифференцирования (PyTorch и TensorFlow)** — вы определяете вычислительный граф и некоторые гиперпараметры, а всё остальное фреймворк делает за вас. Позволяет строить нейросети произвольной сложности.\n",
    "- **Фреймворки готовых моделей (Transformers и DeepPavlov)** — скрывают технические детали самой нейросети и представляют высокоуровневый интерфейс для основных операций: обучения и инференса. Являются обёртками для больших и сложных нейросетей.\n",
    "\n",
    "### ФРЕЙМВОРКИ АВТОМАТИЧЕСКОГО ДИФФЕРЕНЦИРОВАНИЯ \n",
    "\n",
    "Рассмотрим, какие фреймворки представлены на рынке.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Вспоминаем линейную классификацию\n",
    "\n",
    "Прежде чем знакомиться с фреймворками, давайте снова поговорим о том, что такое линейная классификация. Это нам обязательно пригодится далее.\n",
    "\n",
    "### ЛИНЕЙНАЯ КЛАССИФИКАЦИЯ \n",
    "\n",
    "Представьте, что у нас есть признаки x = (x1, x2) и есть выборка положительных и отрицательных точек y ∈ {+1, −1}\n",
    "\n",
    "Нам нужно найти разделяющую гиперплоскость между ними. В данном случае это просто линия. Линия задаётся тремя коэффициентами:\n",
    "\n",
    "Нам нужно найти три коэффициента w, которые зададут линию. Далее мы можем взять точку х и понять, где она находится относительно линии: выше или ниже. Для этого нам нужно узнать знак линейной комбинации. Вектор весов w задаёт нормаль к нашей линии, то есть он перпендикулярен ей (фиолетовый вектор на графике ниже).\n",
    "\n",
    "Линейная комбинация — это скалярное произведение и длина проекции какого-нибудь другого вектора на наш вектор w.\n",
    "\n",
    "Поэтому проекция становится разных знаков. Из этих соображений мы делаем линейный классификатор. Наш алгоритм: \n",
    "\n",
    "Здесь появляется знак нашей линейной комбинации. Настроить линейный классификатор — значит найти эти коэффициенты. \n",
    "\n",
    "### ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ \n",
    "\n",
    "Она тоже решает задачу классификации, но в конце применяется не функция знака, а сигмоидная функция. Она превращает длину проекции в уверенность.\n",
    "\n",
    "Уверенность и неуверенность появляется из-за краевых эффектов: на границе классов может быть какой-то шум, и в классификации точек, которые находятся рядом с красной разделяющей линией, мы не очень уверены. \n",
    "\n",
    "А если мы уходим далеко от линии вглубь классов, то предполагается, что мы более уверены в этом предсказании. Сигмоида делает именно это — превращает длину проекции линейной комбинации в уверенность.\n",
    "\n",
    "Сигмоида устроена не случайным образом:\n",
    "\n",
    "Если длина проекции 0 (точка ровно на красной линии) , то сигмоида даёт . Логистическая регрессия предсказывает вероятность положительного класса. Вероятность отрицательного будет единица минус предсказанная вероятность положительного класса. \n",
    "\n",
    "#### ДРУГОЙ ПРИМЕР \n",
    "\n",
    "Представим, что у нас есть следующая задача:\n",
    "\n",
    "Чтобы решить подобную задачу, мы можем «подпереть» треугольник тремя линиями и сделать алгоритм, используя только логистическую регрессию.\n",
    "\n",
    "Для начала мы отделим минусы слева и построим логистическую регрессию:\n",
    "\n",
    "Эти данные подадим для обучения логистической регрессии и получим коэффициенты красной линии. \n",
    "\n",
    "Отделим остальные минусы:\n",
    "\n",
    "Все коэффициенты мы получили практически вручную. Сейчас у нас есть коэффициенты трёх логистических регрессий, каждая из которых решает свою маленькую подзадачу. \n",
    "\n",
    "Теперь возьмём какую-нибудь точку и посмотрим, какие три предсказания дают эти линии в точке:\n",
    "\n",
    "### ЧТО ДЕЛАТЬ С ЭТИМИ ТРЕМЯ ЗНАЧЕНИЯМИ? \n",
    "\n",
    "В координатах х1 и х2 эта задача не решается. Поэтому полученные коэффициенты мы можем рассматривать как новые координаты. \n",
    "\n",
    "Получим три признака, каждый из которых говорит, где мы находимся относительно каждой стороны треугольника. \n",
    "\n",
    "Давайте возьмём наш целевой признак y, добавим его в нашу новую таблицу, где наши новые признаки с предсказаниями, и попробуем решить её с новыми признаками с помощью линейной логистической регрессии. На новой выборке получим логистическую регрессию:\n",
    "\n",
    "Теперь она даёт нам некоторые коэффициенты и взвешивает уже не признаки, а предсказания. То, что мы получили — простейшая нейросеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.1\n",
    "Почему в логистической регрессии используется Сигмоида, а не Знак (sign)?  \n",
    "\n",
    "Ответ: Сигмоида плавная и непрерывная, что позволяет её дифференцировать верно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Граф вычислений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
